{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype=np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Для исключения ошибки заменяем ноль или единицу на приблизительные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 0:\n",
    "            y_pred[i] = 0.000001\n",
    "        elif y_pred[i] == 1:\n",
    "            y_pred[i] = 0.999999\n",
    "        else:   \n",
    "            y_pred[i] = y_pred[i]\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000500029089e-06"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример применения\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([1, 0], dtype=np.float64)\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-3):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.49595538 -0.14116605  0.64763378  1.52189756] 1.1785958344356262\n",
      "60 [ 0.45334916 -0.30494226  0.64293272  1.4577179 ] 0.9041440834067511\n",
      "120 [ 0.4172077  -0.44203337  0.6370612   1.40327427] 0.709692455534605\n",
      "180 [ 0.38818692 -0.54190395  0.63391148  1.36240168] 0.6032416475719808\n",
      "240 [ 0.36538499 -0.60565721  0.63518206  1.33487199] 0.5574319003707745\n",
      "300 [ 0.34685836 -0.64524836  0.63960383  1.31668649] 0.5381088364834474\n",
      "360 [ 0.33110079 -0.67043641  0.64579465  1.30442975] 0.5289999150718108\n",
      "420 [ 0.31719525 -0.68685563  0.65294234  1.29601454] 0.5240516491673581\n",
      "480 [ 0.30458253 -0.69770741  0.66059774  1.2901844 ] 0.5209399887616784\n",
      "540 [ 0.29290594 -0.70490668  0.66850181  1.28614898] 0.518699955666732\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=600, eta=2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(w, X):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    y_predicted = np.zeros(m)\n",
    "\n",
    "    y_pred_probe = np.squeeze(sigmoid(np.dot(X, w)))\n",
    "\n",
    "    # За порог отнесения к тому или иному классу примем вероятность 0.5\n",
    "    #for i in range(A.shape[0]):\n",
    "    #   if (A[i] > 0.5): \n",
    "    #        y_predicted[i] = 1\n",
    "    #    elif (A[i] <= 0.5):\n",
    "    #        y_predicted[i] = 0\n",
    "\n",
    "    return y_pred_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54819515, 0.61594061, 0.75323294, 0.07547273, 0.79943042,\n",
       "       0.7894202 , 0.78863549, 0.17743516, 0.53087017, 0.81224211])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = calc_pred_proba(W, X_st)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(w, X):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    y_pred = np.zeros(m)\n",
    "\n",
    "    y_pred_probe = np.squeeze(sigmoid(np.dot(X, w)))\n",
    "\n",
    "    #Указываем порог отнесения к тому или иному классу примем вероятность 0.5\n",
    "    for i in range(y_pred_probe.shape[0]):\n",
    "        if (y_pred_probe[i] > 0.5): \n",
    "            y_pred[i] = 1\n",
    "        elif (y_pred_probe[i] <= 0.5):\n",
    "            y_pred[i] = 0\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 1., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = calc_pred(W, X_st)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Модель могла переобучиться. В процессе обучения мы не делили выборку на тренировочную и тестовую"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
